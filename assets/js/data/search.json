[ { "title": "Libtorch 라이브러리 사용 하기", "url": "/posts/Using_a_libtorch_library/", "categories": "Pytorch, Libtorch", "tags": "C++, pytorch, libtorch", "date": "2021-07-02 15:10:00 +0900", "snippet": "최근 Endpoint AI, TinyML등 임베디드 기기에서 neural network 모델을 활용하는 시도가 많이 소개되고있다.Neural network 모델을 개발할 때에는 주로 Python 환경에서 Pytorch나 Tensorflow와 같은 패키지를 사용하는데 임베디드 기기에서는 일반적으로 C나 C++을 주로 활용하기 때문에 모델 학습할 때와 inference 할 때 각각 사용되는 언어가 다르다는 문제가 있다. Libtorch는 Pytorch의 C++ 버전으로 Pytorch를 이용해 학습한 모델을 C++에서도 laod하..." }, { "title": "Jetson nano에서 pytorch build하기", "url": "/posts/Building_pytorch_on_jetson_nano.md/", "categories": "Embedded, Jetson", "tags": "jetson", "date": "2021-07-02 15:10:00 +0900", "snippet": "Jetson nano에서 GPU활용없이 CPU만 사용해서 neural network 모델을 inference를 해야하는 일이 생겼다. 개발해야하는 application은 32ms 길이의 오디오 신호를 16ms 이내에 처리해야 하는데 모델의 inference time이 16ms가 넘는 문제가 있었다. Neural network 모델의 inference time을 줄이는 가장 간단한 방법으로 model compression의 일종인 quantization을 먼저 적용해 보았다.시도한 방법 및 문제점: PC에서 python으로 q..." } ]
