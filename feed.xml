<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://suwoncjh.github.io/</id><title>오디오 신호처리 및 머신러닝</title><subtitle>A minimal, portfolio, sidebar, bootstrap Jekyll theme with responsive web design and focuses on text presentation.</subtitle> <updated>2021-10-07T13:09:59+09:00</updated> <author> <name>Jeonghwan Choi</name> <uri>https://suwoncjh.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://suwoncjh.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="https://suwoncjh.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator> <rights> © 2021 Jeonghwan Choi </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Libtorch 라이브러리 사용 하기</title><link href="https://suwoncjh.github.io/posts/Using_a_libtorch_library/" rel="alternate" type="text/html" title="Libtorch 라이브러리 사용 하기" /><published>2021-07-02T15:10:00+09:00</published> <updated>2021-08-26T11:03:37+09:00</updated> <id>https://suwoncjh.github.io/posts/Using_a_libtorch_library/</id> <content src="https://suwoncjh.github.io/posts/Using_a_libtorch_library/" /> <author> <name>Jeonghwan Choi</name> </author> <category term="Pytorch" /> <category term="Libtorch" /> <summary> 최근 Endpoint AI, TinyML등 임베디드 기기에서 neural network 모델을 활용하는 시도가 많이 소개되고있다. Neural network 모델을 개발할 때에는 주로 Python 환경에서 Pytorch나 Tensorflow와 같은 패키지를 사용하는데 임베디드 기기에서는 일반적으로 C나 C++을 주로 활용하기 때문에 모델 학습할 때와 inference 할 때 각각 사용되는 언어가 다르다는 문제가 있다. Libtorch는 Pytorch의 C++ 버전으로 Pytorch를 이용해 학습한 모델을 C++에서도 laod하여 infernce할 수 있게 해줄 뿐만아니라 직접 새로운 모델 구성 및 학습도 가능하다.(하지만 특수한 경우가 아니라면 C++환경에서 모델을 직접 학습시키는것 보다는 주로 i... </summary> </entry> <entry><title>Jetson nano에서 pytorch build하기</title><link href="https://suwoncjh.github.io/posts/Building_pytorch_on_jetson_nano.md/" rel="alternate" type="text/html" title="Jetson nano에서 pytorch build하기" /><published>2021-07-02T15:10:00+09:00</published> <updated>2021-08-26T11:37:51+09:00</updated> <id>https://suwoncjh.github.io/posts/Building_pytorch_on_jetson_nano.md/</id> <content src="https://suwoncjh.github.io/posts/Building_pytorch_on_jetson_nano.md/" /> <author> <name>Jeonghwan Choi</name> </author> <category term="Embedded" /> <category term="Jetson" /> <summary> Jetson nano에서 GPU활용없이 CPU만 사용해서 neural network 모델을 inference를 해야하는 일이 생겼다. 개발해야하는 application은 32ms 길이의 오디오 신호를 16ms 이내에 처리해야 하는데 모델의 inference time이 16ms가 넘는 문제가 있었다. Neural network 모델의 inference time을 줄이는 가장 간단한 방법으로 model compression의 일종인 quantization을 먼저 적용해 보았다. 시도한 방법 및 문제점: PC에서 python으로 quantization 한 model을 저장 Jetson nano에서 C++ 에서 libtorch로 불러오려는데 모델 로드가 안됨 quantiazation하지 않은... </summary> </entry> </feed>
